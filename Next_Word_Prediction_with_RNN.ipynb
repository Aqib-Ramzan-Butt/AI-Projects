{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aqib-Ramzan-Butt/AI-Projects/blob/main/Next_Word_Prediction_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWMh6bgdRixW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sample Data for Training**"
      ],
      "metadata": {
        "id": "M7H4-RRclIgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"Machine learning algorithms are powerful tools.\"\n",
        "    \"I enjoy exploring new algorithms.\"\n",
        "    \"Learning about AI is captivating.\"\n",
        "    \"Deep learning models can be complex.\"\n",
        "    \"I love understanding how neural networks work.\"\n",
        "    \"The field of data science is evolving rapidly.\"\n",
        "    \"I find artificial intelligence intriguing.\"\n",
        "    \"Studying computer vision is exciting.\"\n",
        "    \"Natural language processing is a fascinating domain.\"\n",
        "    \"I enjoy coding in Python for data science projects.\"\n",
        "    \"Building models is a creative process.\"\n",
        "    \"I love experimenting with different machine learning techniques.\"\n",
        "    \"The potential of AI to transform industries is amazing.\"\n",
        "    \"I enjoy staying updated with the latest tech trends.\"\n",
        "    \"Learning about reinforcement learning is interesting.\"\n",
        "    \"I find predictive modeling to be very useful.\"\n",
        "    \"I love solving problems with data analysis.\"\n",
        "    \"Data preprocessing is a crucial step in machine learning.\"\n",
        "    \"I enjoy reading research papers on deep learning.\"\n",
        "    \"I find optimization techniques fascinating.\"\n",
        "    \"Understanding algorithms helps in developing better solutions.\"\n",
        "    \"I love the challenge of debugging code.\"\n",
        "    \"Machine learning applications are diverse and impactful.\"\n",
        "    \"I enjoy collaborating with others on tech projects.\"\n",
        "    \"Learning new programming languages is fun.\"\n",
        "    \"I love working with large datasets.\"\n",
        "    \"I find feature engineering to be an art.\"\n",
        "    \"Model evaluation is an essential part of machine learning.\"\n",
        "    \"I enjoy attending tech conferences.\"\n",
        "    \"Learning about big data technologies is exciting.\"\n",
        "    \"I love experimenting with neural network architectures.\"\n",
        "    \"I find the theory behind machine learning algorithms interesting.\"\n",
        "    \"I enjoy visualizing data insights.\"\n",
        "    \"Machine learning models can make accurate predictions.\"\n",
        "    \"I love the creativity involved in data storytelling.\"\n",
        "    \"I find unsupervised learning techniques intriguing.\"\n",
        "    \"I enjoy automating tasks with AI.\"\n",
        "    \"Learning about AI ethics is important.\"\n",
        "    \"I love the problem-solving aspect of machine learning.\"\n",
        "    \"I find cloud computing technologies fascinating.\"\n",
        "    \"I enjoy using machine learning for real-world applications.\"\n",
        "    \"I love experimenting with different data preprocessing techniques.\"\n",
        "    \"I find transfer learning to be a powerful approach.\"\n",
        "    \"I enjoy working on machine learning projects.\"\n",
        "    \"Learning about data privacy is crucial.\"\n",
        "    \"I love the innovation happening in the AI field.\"\n",
        "    \"I find data visualization tools useful.\"\n",
        "    \"I enjoy testing and validating machine learning models.\"\n",
        "    \"I love discovering new machine learning applications.\"\n",
        "    \"I find ensemble methods to be effective.\"\n",
        "    \"I enjoy learning from data.\"\n",
        "    \"Machine learning can provide valuable insights.\"\n",
        "    \"I love the interdisciplinary nature of AI.\"\n",
        "    \"I find recommendation systems interesting.\"\n",
        "    \"I enjoy participating in hackathons.\"\n",
        "    \"Learning about neural networks is fascinating.\"\n",
        "    \"I love the potential of AI to solve complex problems.\"\n",
        "    \"I find sentiment analysis intriguing.\"\n",
        "    \"I enjoy implementing machine learning algorithms.\"\n",
        "    \"I love the excitement of discovering patterns in data.\"\n",
        "    \"I find time series analysis challenging.\"\n",
        "    \"I enjoy exploring different types of data.\"\n",
        "    \"Machine learning is transforming various industries.\"\n",
        "    \"I love working on predictive analytics.\"\n",
        "    \"I find anomaly detection to be useful.\"\n",
        "    \"I enjoy studying the mathematics behind machine learning.\"\n",
        "    \"I love the hands-on experience of building models.\"\n",
        "    \"I find clustering techniques interesting.\"\n",
        "    \"I enjoy exploring open-source machine learning libraries.\"\n",
        "    \"Machine learning can automate complex tasks.\"\n",
        "    \"I love the flexibility of machine learning models.\"\n",
        "    \"I find computer vision applications fascinating.\"\n",
        "    \"I enjoy solving real-world problems with AI.\"\n",
        "    \"I love the continuous learning aspect of AI.\"\n",
        "    \"I find reinforcement learning to be challenging.\"\n",
        "    \"I enjoy experimenting with hyperparameter tuning.\"\n",
        "    \"Machine learning can improve decision-making processes.\"\n",
        "    \"I love the creativity involved in feature selection.\"\n",
        "    \"I find generative models to be fascinating.\"\n",
        "    \"I enjoy reading about the latest AI advancements.\"\n",
        "    \"Machine learning can enhance user experiences.\"\n",
        "    \"I love the diversity of machine learning applications.\"\n",
        "    \"I find natural language generation intriguing.\"\n",
        "    \"I enjoy working with text data.\"\n",
        "    \"Machine learning can optimize business processes.\"\n",
        "    \"I love the innovation in AI research.\"\n",
        "    \"I find the concept of machine learning interpretability interesting.\"\n",
        "    \"I enjoy creating machine learning workflows.\"\n",
        "    \"Machine learning can uncover hidden patterns.\"\n",
        "    \"I love the impact of AI on society.\"\n",
        "    \"I find deep reinforcement learning fascinating.\"\n",
        "    \"I enjoy developing custom machine learning solutions.\"\n",
        "    \"Machine learning can improve customer experiences.\"\n",
        "    \"I love the potential of AI in healthcare.\"\n",
        "    \"I find the scalability of machine learning models intriguing.\"\n",
        "    \"I enjoy applying machine learning to finance.\"\n",
        "    \"Machine learning can enhance security measures.\"\n",
        "    \"I love the possibilities of AI in creative industries.\"\n",
        "    \"I find the ethical implications of AI important.\"\n",
        "    \"I enjoy sharing knowledge about machine learning.\"\n",
        "    \"This Free Advance AI Course that is helping alot of students to learn the concepts of AI and provides the detailed guideline on how to learn AI. This course enables the students to make their own projects. Updates them with the state of the art technologies and provide all the necessary knowlegde so that they should not be dependend on anyone to be able to learn anything.\"\n",
        "]"
      ],
      "metadata": {
        "id": "69B45MbBk24S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(total_words)\n",
        "print(tokenizer.word_index)\n",
        "\n",
        "input_sequences = []\n",
        "\n",
        "for line in sentences:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "print(input_sequences)\n"
      ],
      "metadata": {
        "id": "8K83v5Y1ke_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc421967-41cc-46bb-a2bf-8bb2ec9054b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "254\n",
            "{'i': 1, 'learning': 2, 'machine': 3, 'the': 4, 'enjoy': 5, 'love': 6, 'find': 7, 'of': 8, 'ai': 9, 'is': 10, 'to': 11, 'data': 12, 'with': 13, 'in': 14, 'can': 15, 'be': 16, 'about': 17, 'models': 18, 'on': 19, 'fascinating': 20, 'algorithms': 21, 'intriguing': 22, 'techniques': 23, 'interesting': 24, 'applications': 25, 'a': 26, 'projects': 27, 'experimenting': 28, 'and': 29, 'working': 30, 'exploring': 31, 'new': 32, 'deep': 33, 'complex': 34, 'neural': 35, 'different': 36, 'potential': 37, 'industries': 38, 'tech': 39, 'reinforcement': 40, 'useful': 41, 'solving': 42, 'problems': 43, 'analysis': 44, 'technologies': 45, 'learn': 46, 'are': 47, 'powerful': 48, 'tools': 49, 'understanding': 50, 'how': 51, 'networks': 52, 'field': 53, 'science': 54, 'studying': 55, 'computer': 56, 'vision': 57, 'exciting': 58, 'natural': 59, 'language': 60, 'for': 61, 'building': 62, 'creative': 63, 'latest': 64, 'predictive': 65, 'preprocessing': 66, 'crucial': 67, 'reading': 68, 'research': 69, 'developing': 70, 'solutions': 71, 'feature': 72, 'an': 73, 'art': 74, 'behind': 75, 'insights': 76, 'make': 77, 'creativity': 78, 'involved': 79, 'tasks': 80, 'important': 81, 'aspect': 82, 'real': 83, 'world': 84, 'innovation': 85, 'discovering': 86, 'provide': 87, 'patterns': 88, 'challenging': 89, 'improve': 90, 'processes': 91, 'enhance': 92, 'experiences': 93, 'this': 94, 'course': 95, 'that': 96, 'students': 97, 'captivating': 98, 'work': 99, 'evolving': 100, 'rapidly': 101, 'artificial': 102, 'intelligence': 103, 'processing': 104, 'domain': 105, 'coding': 106, 'python': 107, 'process': 108, 'transform': 109, 'amazing': 110, 'staying': 111, 'updated': 112, 'trends': 113, 'modeling': 114, 'very': 115, 'step': 116, 'papers': 117, 'optimization': 118, 'helps': 119, 'better': 120, 'challenge': 121, 'debugging': 122, 'code': 123, 'diverse': 124, 'impactful': 125, 'collaborating': 126, 'others': 127, 'programming': 128, 'languages': 129, 'fun': 130, 'large': 131, 'datasets': 132, 'engineering': 133, 'model': 134, 'evaluation': 135, 'essential': 136, 'part': 137, 'attending': 138, 'conferences': 139, 'big': 140, 'network': 141, 'architectures': 142, 'theory': 143, 'visualizing': 144, 'accurate': 145, 'predictions': 146, 'storytelling': 147, 'unsupervised': 148, 'automating': 149, 'ethics': 150, 'problem': 151, 'cloud': 152, 'computing': 153, 'using': 154, 'transfer': 155, 'approach': 156, 'privacy': 157, 'happening': 158, 'visualization': 159, 'testing': 160, 'validating': 161, 'ensemble': 162, 'methods': 163, 'effective': 164, 'from': 165, 'valuable': 166, 'interdisciplinary': 167, 'nature': 168, 'recommendation': 169, 'systems': 170, 'participating': 171, 'hackathons': 172, 'solve': 173, 'sentiment': 174, 'implementing': 175, 'excitement': 176, 'time': 177, 'series': 178, 'types': 179, 'transforming': 180, 'various': 181, 'analytics': 182, 'anomaly': 183, 'detection': 184, 'mathematics': 185, 'hands': 186, 'experience': 187, 'clustering': 188, 'open': 189, 'source': 190, 'libraries': 191, 'automate': 192, 'flexibility': 193, 'continuous': 194, 'hyperparameter': 195, 'tuning': 196, 'decision': 197, 'making': 198, 'selection': 199, 'generative': 200, 'advancements': 201, 'user': 202, 'diversity': 203, 'generation': 204, 'text': 205, 'optimize': 206, 'business': 207, 'concept': 208, 'interpretability': 209, 'creating': 210, 'workflows': 211, 'uncover': 212, 'hidden': 213, 'impact': 214, 'society': 215, 'custom': 216, 'customer': 217, 'healthcare': 218, 'scalability': 219, 'applying': 220, 'finance': 221, 'security': 222, 'measures': 223, 'possibilities': 224, 'ethical': 225, 'implications': 226, 'sharing': 227, 'knowledge': 228, 'free': 229, 'advance': 230, 'helping': 231, 'alot': 232, 'concepts': 233, 'provides': 234, 'detailed': 235, 'guideline': 236, 'enables': 237, 'their': 238, 'own': 239, 'updates': 240, 'them': 241, 'state': 242, 'all': 243, 'necessary': 244, 'knowlegde': 245, 'so': 246, 'they': 247, 'should': 248, 'not': 249, 'dependend': 250, 'anyone': 251, 'able': 252, 'anything': 253}\n",
            "[[  0   0   0 ...   0   3   2]\n",
            " [  0   0   0 ...   3   2  21]\n",
            " [  0   0   0 ...   2  21  47]\n",
            " ...\n",
            " [  0   0   3 ...  16 252  11]\n",
            " [  0   3   2 ... 252  11  46]\n",
            " [  3   2  21 ...  11  46 253]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# ... (Data loading and preprocessing)\n",
        "\n",
        "def unet(input_size=(256, 256, 3)):\n",
        "    inputs = tf.keras.Input(shape=input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    # ... (Similar blocks for deeper layers)\n",
        "\n",
        "    # Decoder\n",
        "    up7 = UpSampling2D(size=(2, 2))(conv7)\n",
        "    merge7 = Concatenate()([up7, conv6])\n",
        "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(merge7)\n",
        "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    # ... (Similar blocks for shallower layers)\n",
        "\n",
        "    outputs = Conv2D(1, 1, activation='sigmoid')(conv1)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "s1c9r_0kb8Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = input_sequences[:, :-1]\n",
        "print(\"Input Data: \",X)\n",
        "\n",
        "y = input_sequences[:, -1]\n",
        "print(\"Labels: \",y)\n",
        "\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
      ],
      "metadata": {
        "id": "TYdcZwZakiUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45d92c1-b476-42aa-e343-4cdc3e4725e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Data:  [[  0   0   0 ...   0   0   3]\n",
            " [  0   0   0 ...   0   3   2]\n",
            " [  0   0   0 ...   3   2  21]\n",
            " ...\n",
            " [  0   0   3 ...  11  16 252]\n",
            " [  0   3   2 ...  16 252  11]\n",
            " [  3   2  21 ... 252  11  46]]\n",
            "Labels:  [  2  21  47  48  49   1   5  31  32  21   2  17   9  10  98  33   2  18\n",
            "  15  16  34   1   6  50  51  35  52  99   4  53   8  12  54  10 100 101\n",
            "   1   7 102 103  22  55  56  57  10  58  59  60 104  10  26  20 105   1\n",
            "   5 106  14 107  61  12  54  27  62  18  10  26  63 108   1   6  28  13\n",
            "  36   3   2  23   4  37   8   9  11 109  38  10 110   1   5 111 112  13\n",
            "   4  64  39 113   2  17  40   2  10  24   1   7  65 114  11  16 115  41\n",
            "   1   6  42  43  13  12  44  12  66  10  26  67 116  14   3   2   1   5\n",
            "  68  69 117  19  33   2   1   7 118  23  20  50  21 119  14  70 120  71\n",
            "   1   6   4 121   8 122 123   3   2  25  47 124  29 125   1   5 126  13\n",
            " 127  19  39  27   2  32 128 129  10 130   1   6  30  13 131 132   1   7\n",
            "  72 133  11  16  73  74 134 135  10  73 136 137   8   3   2   1   5 138\n",
            "  39 139   2  17 140  12  45  10  58   1   6  28  13  35 141 142   1   7\n",
            "   4 143  75   3   2  21  24   1   5 144  12  76   3   2  18  15  77 145\n",
            " 146   1   6   4  78  79  14  12 147   1   7 148   2  23  22   1   5 149\n",
            "  80  13   9   2  17   9 150  10  81   1   6   4 151  42  82   8   3   2\n",
            "   1   7 152 153  45  20   1   5 154   3   2  61  83  84  25   1   6  28\n",
            "  13  36  12  66  23   1   7 155   2  11  16  26  48 156   1   5  30  19\n",
            "   3   2  27   2  17  12 157  10  67   1   6   4  85 158  14   4   9  53\n",
            "   1   7  12 159  49  41   1   5 160  29 161   3   2  18   1   6  86  32\n",
            "   3   2  25   1   7 162 163  11  16 164   1   5   2 165  12   3   2  15\n",
            "  87 166  76   1   6   4 167 168   8   9   1   7 169 170  24   1   5 171\n",
            "  14 172   2  17  35  52  10  20   1   6   4  37   8   9  11 173  34  43\n",
            "   1   7 174  44  22   1   5 175   3   2  21   1   6   4 176   8  86  88\n",
            "  14  12   1   7 177 178  44  89   1   5  31  36 179   8  12   3   2  10\n",
            " 180 181  38   1   6  30  19  65 182   1   7 183 184  11  16  41   1   5\n",
            "  55   4 185  75   3   2   1   6   4 186  19 187   8  62  18   1   7 188\n",
            "  23  24   1   5  31 189 190   3   2 191   3   2  15 192  34  80   1   6\n",
            "   4 193   8   3   2  18   1   7  56  57  25  20   1   5  42  83  84  43\n",
            "  13   9   1   6   4 194   2  82   8   9   1   7  40   2  11  16  89   1\n",
            "   5  28  13 195 196   3   2  15  90 197 198  91   1   6   4  78  79  14\n",
            "  72 199   1   7 200  18  11  16  20   1   5  68  17   4  64   9 201   3\n",
            "   2  15  92 202  93   1   6   4 203   8   3   2  25   1   7  59  60 204\n",
            "  22   1   5  30  13 205  12   3   2  15 206 207  91   1   6   4  85  14\n",
            "   9  69   1   7   4 208   8   3   2 209  24   1   5 210   3   2 211   3\n",
            "   2  15 212 213  88   1   6   4 214   8   9  19 215   1   7  33  40   2\n",
            "  20   1   5  70 216   3   2  71   3   2  15  90 217  93   1   6   4  37\n",
            "   8   9  14 218   1   7   4 219   8   3   2  18  22   1   5 220   3   2\n",
            "  11 221   3   2  15  92 222 223   1   6   4 224   8   9  14  63  38   1\n",
            "   7   4 225 226   8   9  81   1   5 227 228  17   3   2  94 229 230   9\n",
            "  95  96  10 231 232   8  97  11  46   4 233   8   9  29 234   4 235 236\n",
            "  19  51  11  46   9  94  95 237   4  97  11  77 238 239  27 240 241  13\n",
            "   4 242   8   4  74  45  29  87 243   4 244 245 246  96 247 248 249  16\n",
            " 250  19 251  11  16 252  11  46 253]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(total_words, 10, input_length=max_sequence_len-1),\n",
        "\n",
        "    SimpleRNN(60),\n",
        "\n",
        "    Dense(total_words, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "mqKCUHsvkkjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff8651fc-ea87-4c9b-f251-76ea688537a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "f269CJTikmo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=50, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DrcVT99krU6",
        "outputId": "c07c0e43-3a27-4d33-8fda-d5ef384e6b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 117ms/step - accuracy: 0.0155 - loss: 5.4932\n",
            "Epoch 2/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.0388 - loss: 5.1328\n",
            "Epoch 3/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.0778 - loss: 4.7506\n",
            "Epoch 4/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.0948 - loss: 4.6702\n",
            "Epoch 5/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.1079 - loss: 4.6424\n",
            "Epoch 6/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.0995 - loss: 4.5594\n",
            "Epoch 7/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.0816 - loss: 4.6712\n",
            "Epoch 8/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.0969 - loss: 4.5752\n",
            "Epoch 9/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.0784 - loss: 4.6581\n",
            "Epoch 10/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.0808 - loss: 4.6246\n",
            "Epoch 11/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.0902 - loss: 4.5249\n",
            "Epoch 12/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.1349 - loss: 4.5751\n",
            "Epoch 13/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.1948 - loss: 4.3143\n",
            "Epoch 14/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.2251 - loss: 4.2389\n",
            "Epoch 15/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2049 - loss: 4.2885\n",
            "Epoch 16/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.1900 - loss: 4.0930\n",
            "Epoch 17/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2146 - loss: 3.9891\n",
            "Epoch 18/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2177 - loss: 3.9119\n",
            "Epoch 19/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2513 - loss: 3.7367\n",
            "Epoch 20/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.2517 - loss: 3.6947\n",
            "Epoch 21/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2801 - loss: 3.5794\n",
            "Epoch 22/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.2910 - loss: 3.4776\n",
            "Epoch 23/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.3163 - loss: 3.3578\n",
            "Epoch 24/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.3051 - loss: 3.3529\n",
            "Epoch 25/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.3332 - loss: 3.1915\n",
            "Epoch 26/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.3252 - loss: 3.1963\n",
            "Epoch 27/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.3327 - loss: 3.1084\n",
            "Epoch 28/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.3683 - loss: 3.1219\n",
            "Epoch 29/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.3588 - loss: 3.3432\n",
            "Epoch 30/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.3668 - loss: 3.1778\n",
            "Epoch 31/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.3753 - loss: 2.9852\n",
            "Epoch 32/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.3810 - loss: 2.8552\n",
            "Epoch 33/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4066 - loss: 2.6582\n",
            "Epoch 34/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4313 - loss: 2.5710\n",
            "Epoch 35/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.4104 - loss: 2.6405\n",
            "Epoch 36/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.4127 - loss: 2.5448\n",
            "Epoch 37/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.4540 - loss: 2.4278\n",
            "Epoch 38/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.4604 - loss: 2.4212\n",
            "Epoch 39/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4712 - loss: 2.3267\n",
            "Epoch 40/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.4936 - loss: 2.3029\n",
            "Epoch 41/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.4921 - loss: 2.2622\n",
            "Epoch 42/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.5075 - loss: 2.1895\n",
            "Epoch 43/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.5047 - loss: 2.1743\n",
            "Epoch 44/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5106 - loss: 2.1266\n",
            "Epoch 45/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5508 - loss: 1.9970\n",
            "Epoch 46/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.5637 - loss: 1.9787\n",
            "Epoch 47/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.6040 - loss: 1.8521\n",
            "Epoch 48/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.6097 - loss: 1.8746\n",
            "Epoch 49/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6213 - loss: 1.8145\n",
            "Epoch 50/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.6030 - loss: 1.7702\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f4b603769b0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction:**\n",
        "\n",
        "**Seed Text Conversion:** The input text (seed_text) is converted to a sequence of integers using the tokenizer.\n",
        "\n",
        "**Padding:** The integer sequence is padded to ensure it matches the model's expected input length.\n",
        "\n",
        "**Prediction:** The model predicts the probability of each word in the vocabulary as the next word.\n",
        "\n",
        "**Selection and Update:** The word with the highest probability is selected, converted back to a word, and appended to the seed text.\n",
        "\n",
        "**Iterative Prediction:** This process can be repeated for a specified number of words (next_words)."
      ],
      "metadata": {
        "id": "mYaDIFGlnPSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(seed_text, next_words=1):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\n",
        "        predicted = model.predict(token_list, verbose=0)\n",
        "\n",
        "        predicted_word_index = np.argmax(predicted, axis=-1)[0]\n",
        "\n",
        "        predicted_word = tokenizer.index_word[predicted_word_index]\n",
        "\n",
        "        seed_text += \" \" + predicted_word\n",
        "\n",
        "    return seed_text\n"
      ],
      "metadata": {
        "id": "fRWQZDi9kuWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_next_word(\"machine lEARNING can enhance\"))"
      ],
      "metadata": {
        "id": "WlvrbPvVi77y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c59963b-b48b-4021-856b-c28e66835673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "machine lEARNING can enhance decision\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}